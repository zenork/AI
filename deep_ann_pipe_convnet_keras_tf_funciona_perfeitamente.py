# -*- coding: utf-8 -*-
"""DEEP_ANN_PIPE_CONVNET_KERAS_TF_FUNCIONA_PERFEITAMENTE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XEp6FfhEFqizXq-7_P3Ne7EperEnw6QX
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt


import cv2   #to resize the image
import os  # to play with directories
import numpy as np
from random import shuffle # to shuffle the data
from tqdm import tqdm #for professional looping with a progress bar (to see the iterations per second and the time running)
#esse tqdm só é útil se o seu loop estiver demorando, daí vc pode ver o progresso dele


#o pré-processamento de imagens requer carregar as imagens e organizar elas, cada imagem
#tem um conjunto de atributos(features) e de legenda(label)

IMG_SIZE = 40 # tamanho de resolução da imagem 2D em um dos eixos, aqui eu assumi que a imagem seria em formato de um quadrado.
N_img = 50 # Quantidade de imagens que você irá carregar para treinar a rede, certifique-se de digitar o número com a quantidade EXATA.

LR =1e-2 #learning rate of NN

from google.colab import files
def getLocalFiles():
    _files = files.upload()
    if len(_files) >0:
       for k,v in _files.items():
         open(k,'wb').write(v)
getLocalFiles()

import cv2
import numpy as np
from matplotlib import pyplot as plt








img_name_list = [] #armazenarei o nome de cada imagem em uma lista
list_img = [] # armazenarei as imagens que usarei para treinar a rede, em uma lista.
for i in range (1, N_img + 1):
  
  img_name = str( 'tubo_' + str(i) + '_ANN' + '.jpg' ) #coloquei para ler manualmente o nome da imagem que eu importei da pasta de imagens que irei utilizar para treinar a rede
  
  img = cv2.imread(img_name) # o "cv2.imread" carrega a imagem, logo eu estou salvando a imagem na variavel "img". Obviamente se vc nao carregou a imagem, essa variavel sera do tipo None
  
  
  if img is not None: 
        
    img = cv2.resize(img,(IMG_SIZE,IMG_SIZE)) #agora que a imagem foi salva, muda-se sua resolução: para IMG_SIZE que foi declarado anteriormente, a quantidade de pixels é a multiplicação de X por Y, nesse caso, IMG_SIZE*IMG_SIZE, ou seja, o comprimento desta variável que estamos armazenando dará o valor de pixels.
    
    
   
    list_img.append(img) # armazenando as imagens de uma por uma ao longo da execução do loop, em formato de list np.array (matriz) ao invés de list
    #as imagens são armazenadas sob a forma de números pixels
    
    img_name_list.append(img_name)
    
    
    #training_data.append([np.array(img), np.array(label)]) , no nosso caso não temos label, pois só temos 1 classe em nossas imagens, que são as tubulações
  else:
    print("\n")
    print("Você esqueceu de carregar a imagem " + "chamada " + img_name)
    print("\n")
    print("Tente carregar todas as imagens novamente e execute novamente o programa, obrigado")
    print("\n")
  
 


  
#Uma vez que já temos nossas imagens carregadas para treino, iremos salvar elas em uma matriz de treino  

x = list_img # a matriz de treino é a própria list_img



#utilizaremos np.zeros apenas para não dar problema de index inexistente na hora de alocar um valor a uma determinada posição da matriz
y=np.zeros(len(img_name_list))   #armazenando os labels em y,  np.zeros: Return a new array of given shape and type, filled with zeros.
for i in range(len(img_name_list)):
  if 'tubo' in img_name_list[i]:  #se tiver a palavra "tubo" na imagem i, adicione o label 0 para esta imagem, o pensamento é esse...
    y[i]=0    # para cada elemento da matriz imagem de treino, terá um label.
  else:
    y[i]=1    # o label 1 não vai ser dado pra nenhuma imagem pois só tem-se 50 imagens apenas de tubos, ou seja, so temos 1 classe.


print(y)
print('len(x) é',len(x))
print('len(y) é',len(y))
print(len(img_name_list))

print(type(list_img))

print(x[30].shape)   # a dimensão é (IMG_SIZE X IMG_SIZE X 3), o último termo equivale a 3, que significa 3 RGB (red-green-blue), cores que que compõem um pixel.

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt
from PIL import Image
import numpy as np
import pandas as pd
import os 
import cv2
import re, random

!pip install keras-tqdm
import keras
from tqdm import tqdm_notebook
from random import shuffle
import shutil
import tensorflow as tf
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator
from keras_tqdm import TQDMNotebookCallback
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.constraints import maxnorm
from keras.optimizers import SGD
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils
from keras.callbacks import Callback
from keras.preprocessing.image import img_to_array, load_img
from keras import layers, models, optimizers
from keras import backend as K
from sklearn.metrics import confusion_matrix
import itertools

import matplotlib.image as mpimg
import seaborn as sns
# %matplotlib inline

x_train, x_test,y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=1) # train_test_split: Split arrays or matrices into random train and test subsets
#test_size = 0.2 é usado para que 20% dos dados sejam utilizados para teste . random_state=1 é apenas para escolha do gerador de numeros aleatorios da função imbutida.

x_train=np.array(x_train) # passando a list para np.array que é o argumento que o keras e o tensor flow aceita como argumento de entrada

x_test=np.array(x_test)

print(x_train.shape)




'''
x_train = tf.image.resize_images(x_train, [32, 32])    # esse comando serve apenas para caso vc quisesse mudar a resolução das imagens 2D eixo X pelo eixo Y
x_test = tf.image.resize_images(x_test, [32, 32])
'''

print(x_train.shape)

#Normalizando os valores do pixel contidos na matriz das imagens


train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True) # 255 é o valor máximo numérico numa escala de cor que o pixel de uma imagem pode assumir. o range varia de 0 até 255. 0 é preto e 255 é branco. 

val_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

#PREPARANDO A ESTRUTURA DA REDE NEURAL DE CONVOLUÇÃO

# Importing the Keras libraries and packages
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense

# Initialising the CNN
classifier = Sequential()

# Step 1 - Convolution
classifier.add(Conv2D(32, (3, 3), input_shape = (IMG_SIZE, IMG_SIZE, 3), activation = 'relu')) # essa dimensão "3" do lado de IMG_SIZE se refere ao RGB do pixel

# Step 2 - Pooling
classifier.add(MaxPooling2D(pool_size = (2, 2)))

# Adding a second convolutional layer
classifier.add(Conv2D(32, (3, 3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size = (2, 2)))

# Step 3 - Flattening
classifier.add(Flatten())

# Step 4 - Full connection
classifier.add(Dense(units = 128, activation = 'relu'))
classifier.add(Dense(units = 1, activation = 'sigmoid'))

# Compiling the CNN
classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

# Part 2 - Fitting the CNN to the images

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255)



'''training_set = train_datagen.flow_from_directory('dataset/training_set',
                                                 target_size = (IMG_SIZE, IMG_SIZE),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

test_set = test_datagen.flow_from_directory('dataset/test_set',
                                            target_size = (IMG_SIZE, IMG_SIZE),
                                            batch_size = 32,
                                            class_mode = 'binary')'''

batch_size = 32
training_set = train_datagen.flow(x_train, y_train, batch_size=batch_size)
test_set = val_datagen.flow(x_test,y_test, batch_size=batch_size)

classifier.fit_generator(training_set,
                         steps_per_epoch =10,
                         epochs = 10,
                         validation_data = test_set,
                         validation_steps = 50)



#COMMENTS: ->Increasing the number of layers of a neural network (NN) make it becomesa deep NN;
# -> Convolutional NN(Convnet) are specifically to image recognition;
#-> Convnet are inspired by the animal visual Cortex;
#-> When you use the dropout method you remove overfitting problem, but you put the problem over far from reality, so you have to put a small rate of dropout.
#->Example: An image has a resolution of X x Y of size, so it has X . Y pixels. Ex.: 50 x 50 = 2500 pixels;
#-> It is needed X . Y nodes in the first layer to process each pixel;
#Higher the number of pixels more inefficient is the training;

#The components of convnets, as convolution layers, normalization layers, pooling layers are used to extract the high level features out of the images,
# and then are feeded to a fully connected NN or any other classifier for that matter.

